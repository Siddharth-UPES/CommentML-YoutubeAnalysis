{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ha3O-_d__JN1",
    "outputId": "0e862c02-49f8-4f08-9ef8-a58edf96563b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==3.5.1 (from mlflow)\n",
      "  Downloading mlflow_skinny-3.5.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.5.1 (from mlflow)\n",
      "  Downloading mlflow_tracing-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow)\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (3.1.0)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.17.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (44.0.1)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (2.1.3)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<22,>=4.0.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (19.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (1.15.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow) (2.0.39)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (3.0.0)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading databricks_sdk-0.71.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading fastapi-0.120.4-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (8.5.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<26 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (2.10.3)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (1.1.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow) (4.12.2)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==3.5.1->mlflow) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from cryptography<47,>=43.0.0->mlflow) (1.17.1)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading google_auth-2.42.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (308)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Collecting starlette<0.50.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.5.1->mlflow) (3.21.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.5.1->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (0.4.8)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow) (4.7.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow) (1.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from uvicorn<1->mlflow-skinny==3.5.1->mlflow) (0.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\suraj\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->Flask<4->mlflow) (3.0.2)\n",
      "Downloading mlflow-3.5.1-py3-none-any.whl (8.8 MB)\n",
      "   ---------------------------------------- 0.0/8.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.8/8.8 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.9/8.8 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.0/8.8 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.8 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.8/8.8 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-3.5.1-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 2.1/2.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading mlflow_tracing-3.5.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 1.0/1.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading alembic-1.17.1-py3-none-any.whl (247 kB)\n",
      "Downloading databricks_sdk-0.71.0-py3-none-any.whl (752 kB)\n",
      "   ---------------------------------------- 0.0/752.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 752.6/752.6 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.120.4-py3-none-any.whl (108 kB)\n",
      "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading google_auth-2.42.1-py2.py3-none-any.whl (222 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: waitress, sqlparse, rsa, opentelemetry-proto, Mako, graphql-core, annotated-doc, uvicorn, starlette, opentelemetry-api, graphql-relay, google-auth, docker, alembic, opentelemetry-semantic-conventions, graphene, Flask-CORS, fastapi, databricks-sdk, opentelemetry-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
      "\n",
      "   - --------------------------------------  1/23 [sqlparse]\n",
      "   --- ------------------------------------  2/23 [rsa]\n",
      "   ----- ----------------------------------  3/23 [opentelemetry-proto]\n",
      "   ----- ----------------------------------  3/23 [opentelemetry-proto]\n",
      "   ------ ---------------------------------  4/23 [Mako]\n",
      "   ------ ---------------------------------  4/23 [Mako]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   -------- -------------------------------  5/23 [graphql-core]\n",
      "   ------------ ---------------------------  7/23 [uvicorn]\n",
      "   ------------ ---------------------------  7/23 [uvicorn]\n",
      "   ------------ ---------------------------  7/23 [uvicorn]\n",
      "   ------------- --------------------------  8/23 [starlette]\n",
      "   ------------- --------------------------  8/23 [starlette]\n",
      "   ------------- --------------------------  8/23 [starlette]\n",
      "   --------------- ------------------------  9/23 [opentelemetry-api]\n",
      "   --------------- ------------------------  9/23 [opentelemetry-api]\n",
      "   --------------- ------------------------  9/23 [opentelemetry-api]\n",
      "   ----------------- ---------------------- 10/23 [graphql-relay]\n",
      "   ------------------- -------------------- 11/23 [google-auth]\n",
      "   ------------------- -------------------- 11/23 [google-auth]\n",
      "   ------------------- -------------------- 11/23 [google-auth]\n",
      "   ------------------- -------------------- 11/23 [google-auth]\n",
      "   ------------------- -------------------- 11/23 [google-auth]\n",
      "   -------------------- ------------------- 12/23 [docker]\n",
      "   -------------------- ------------------- 12/23 [docker]\n",
      "   -------------------- ------------------- 12/23 [docker]\n",
      "   -------------------- ------------------- 12/23 [docker]\n",
      "   -------------------- ------------------- 12/23 [docker]\n",
      "   -------------------- ------------------- 12/23 [docker]\n",
      "   ---------------------- ----------------- 13/23 [alembic]\n",
      "   ---------------------- ----------------- 13/23 [alembic]\n",
      "   ---------------------- ----------------- 13/23 [alembic]\n",
      "   ---------------------- ----------------- 13/23 [alembic]\n",
      "   ---------------------- ----------------- 13/23 [alembic]\n",
      "   ---------------------- ----------------- 13/23 [alembic]\n",
      "   -------------------- ------------ 14/23 [opentelemetry-semantic-conventions]\n",
      "   -------------------- ------------ 14/23 [opentelemetry-semantic-conventions]\n",
      "   -------------------- ------------ 14/23 [opentelemetry-semantic-conventions]\n",
      "   -------------------- ------------ 14/23 [opentelemetry-semantic-conventions]\n",
      "   -------------------- ------------ 14/23 [opentelemetry-semantic-conventions]\n",
      "   -------------------- ------------ 14/23 [opentelemetry-semantic-conventions]\n",
      "   -------------------- ------------ 14/23 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   -------------------------- ------------- 15/23 [graphene]\n",
      "   ----------------------------- ---------- 17/23 [fastapi]\n",
      "   ----------------------------- ---------- 17/23 [fastapi]\n",
      "   ----------------------------- ---------- 17/23 [fastapi]\n",
      "   ----------------------------- ---------- 17/23 [fastapi]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   ------------------------------- -------- 18/23 [databricks-sdk]\n",
      "   --------------------------------- ------ 19/23 [opentelemetry-sdk]\n",
      "   --------------------------------- ------ 19/23 [opentelemetry-sdk]\n",
      "   --------------------------------- ------ 19/23 [opentelemetry-sdk]\n",
      "   --------------------------------- ------ 19/23 [opentelemetry-sdk]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ---------------------------------- ----- 20/23 [mlflow-tracing]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   ------------------------------------ --- 21/23 [mlflow-skinny]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   -------------------------------------- - 22/23 [mlflow]\n",
      "   ---------------------------------------- 23/23 [mlflow]\n",
      "\n",
      "Successfully installed Flask-CORS-6.0.1 Mako-1.3.10 alembic-1.17.1 annotated-doc-0.0.3 databricks-sdk-0.71.0 docker-7.1.0 fastapi-0.120.4 google-auth-2.42.1 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 mlflow-3.5.1 mlflow-skinny-3.5.1 mlflow-tracing-3.5.1 opentelemetry-api-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 rsa-4.9.1 sqlparse-0.5.3 starlette-0.49.3 uvicorn-0.38.0 waitress-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTr4F1Vj_OPp",
    "outputId": "0d8c251f-2bfe-4c5b-8a0a-6b43be90e3d9"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://ec2-54-196-109-131.compute-1.amazonaws.com:5000/\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gT5_m6-_Rrad"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "u3hxNz36b6_7",
    "outputId": "b89ead63-34b7-4463-a0fb-27c36f9fba0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-Apko0jpb87p"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BIzRs9YZcAlR"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BDy25RHPcDQH"
   },
   "outputs": [],
   "source": [
    "df = df[~(df['clean_comment'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RS5937JRcFZY"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_um_s1pc2Bo",
    "outputId": "6f5c00ba-8276-40e6-f465-0198c426b71e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Suraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Suraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure necessary NLTK data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zsbpkHfIc39y"
   },
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_comment(comment):\n",
    "    # Convert to lowercase\n",
    "    comment = comment.lower()\n",
    "\n",
    "    # Remove trailing and leading whitespaces\n",
    "    comment = comment.strip()\n",
    "\n",
    "    # Remove newline characters\n",
    "    comment = re.sub(r'\\n', ' ', comment)\n",
    "\n",
    "    # Remove non-alphanumeric characters, except punctuation\n",
    "    comment = re.sub(r'[^A-Za-z0-9\\s!?.,]', '', comment)\n",
    "\n",
    "    # Remove stopwords but retain important ones for sentiment analysis\n",
    "    stop_words = set(stopwords.words('english')) - {'not', 'but', 'however', 'no', 'yet'}\n",
    "    comment = ' '.join([word for word in comment.split() if word not in stop_words])\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    comment = ' '.join([lemmatizer.lemmatize(word) for word in comment.split()])\n",
    "\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3I0cY3nNc6wK"
   },
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the 'clean_comment' column\n",
    "df['clean_comment'] = df['clean_comment'].apply(preprocess_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rQoUyz9Rc9Az",
    "outputId": "4f2e513a-341d-402e-9ec8-f32649b2460a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0  family mormon never tried explain still stare ...         1\n",
       "1  buddhism much lot compatible christianity espe...         1\n",
       "2  seriously say thing first get complex explain ...        -1\n",
       "3  learned want teach different focus goal not wr...         0\n",
       "4  benefit may want read living buddha living chr...         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GRF5A1ZCdBck"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EAKFpLNig7B2"
   },
   "outputs": [],
   "source": [
    "# Step 1: Vectorize the comments using Bag of Words (CountVectorizer)\n",
    "vectorizer = CountVectorizer(max_features=10000)  # Bag of Words model with a limit of 1000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DEbBOYO9g-jq"
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['clean_comment']).toarray()\n",
    "y = df['category']  # Assuming 'sentiment' is the target variable (0 or 1 for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_clGUqHEhBf0",
    "outputId": "c0d2cbca-0a55-4222-aac3-9528d347009c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFtHOYDehF3A",
    "outputId": "c7a141a6-9d70-48cb-faec-f57355e434de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793, 10000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "bXvMvOOshMlc",
    "outputId": "7f7367c0-4b8f-4ed2-f412-acf4df536737"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2       -1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "37244    0\n",
       "37245    1\n",
       "37246    0\n",
       "37247    1\n",
       "37248    0\n",
       "Name: category, Length: 36793, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efCnt68yhNs8",
    "outputId": "eb932939-789e-4974-af97-cbab71bbe70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "op6TubXQhPfw"
   },
   "outputs": [],
   "source": [
    "# Step 2: Set up the MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://ec2-54-196-109-131.compute-1.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIyYuCwVhUeE",
    "outputId": "06a703c9-1438-455c-feb4-fc79f73639bb"
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "API request to http://ec2-54-196-109-131.compute-1.amazonaws.com:5000/api/2.0/mlflow/experiments/get-by-name failed with timeout exception HTTPConnectionPool(host='ec2-54-196-109-131.compute-1.amazonaws.com', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=RF+Baseline (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001D6E1DBF350>, 'Connection to ec2-54-196-109-131.compute-1.amazonaws.com timed out. (connect timeout=120)')). To increase the timeout, set the environment variable MLFLOW_HTTP_REQUEST_TIMEOUT (default: 120) to a larger value.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    199\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    201\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    202\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    203\u001b[0m     )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    494\u001b[0m         method,\n\u001b[0;32m    495\u001b[0m         url,\n\u001b[0;32m    496\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    497\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    498\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    499\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    500\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    501\u001b[0m         enforce_content_length\u001b[38;5;241m=\u001b[39menforce_content_length,\n\u001b[0;32m    502\u001b[0m     )\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:445\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders()\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1333\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1093\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1096\u001b[0m \n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1037\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:276\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:207\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPConnection object at 0x000001D6E1DBF350>, 'Connection to ec2-54-196-109-131.compute-1.amazonaws.com timed out. (connect timeout=120)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    872\u001b[0m         method,\n\u001b[0;32m    873\u001b[0m         url,\n\u001b[0;32m    874\u001b[0m         body,\n\u001b[0;32m    875\u001b[0m         headers,\n\u001b[0;32m    876\u001b[0m         retries,\n\u001b[0;32m    877\u001b[0m         redirect,\n\u001b[0;32m    878\u001b[0m         assert_same_host,\n\u001b[0;32m    879\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    880\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    881\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    882\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    883\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    884\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    885\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    872\u001b[0m         method,\n\u001b[0;32m    873\u001b[0m         url,\n\u001b[0;32m    874\u001b[0m         body,\n\u001b[0;32m    875\u001b[0m         headers,\n\u001b[0;32m    876\u001b[0m         retries,\n\u001b[0;32m    877\u001b[0m         redirect,\n\u001b[0;32m    878\u001b[0m         assert_same_host,\n\u001b[0;32m    879\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    880\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    881\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    882\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    883\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    884\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    885\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 871 (4 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    872\u001b[0m         method,\n\u001b[0;32m    873\u001b[0m         url,\n\u001b[0;32m    874\u001b[0m         body,\n\u001b[0;32m    875\u001b[0m         headers,\n\u001b[0;32m    876\u001b[0m         retries,\n\u001b[0;32m    877\u001b[0m         redirect,\n\u001b[0;32m    878\u001b[0m         assert_same_host,\n\u001b[0;32m    879\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    880\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    881\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    882\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    883\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    884\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    885\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    886\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    842\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    843\u001b[0m )\n\u001b[0;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='ec2-54-196-109-131.compute-1.amazonaws.com', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=RF+Baseline (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001D6E1DBF350>, 'Connection to ec2-54-196-109-131.compute-1.amazonaws.com timed out. (connect timeout=120)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:232\u001b[0m, in \u001b[0;36mhttp_request\u001b[1;34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_http_response_with_retries(\n\u001b[0;32m    233\u001b[0m         method,\n\u001b[0;32m    234\u001b[0m         url,\n\u001b[0;32m    235\u001b[0m         max_retries,\n\u001b[0;32m    236\u001b[0m         backoff_factor,\n\u001b[0;32m    237\u001b[0m         backoff_jitter,\n\u001b[0;32m    238\u001b[0m         retry_codes,\n\u001b[0;32m    239\u001b[0m         raise_on_status,\n\u001b[0;32m    240\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    241\u001b[0m         verify\u001b[38;5;241m=\u001b[39mhost_creds\u001b[38;5;241m.\u001b[39mverify,\n\u001b[0;32m    242\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    243\u001b[0m         respect_retry_after_header\u001b[38;5;241m=\u001b[39mrespect_retry_after_header,\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    245\u001b[0m     )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m to:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\request_utils.py:237\u001b[0m, in \u001b[0;36m_get_http_response_with_retries\u001b[1;34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m allow_redirects \u001b[38;5;241m=\u001b[39m env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method, url, allow_redirects\u001b[38;5;241m=\u001b[39mallow_redirects, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[1;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: HTTPConnectionPool(host='ec2-54-196-109-131.compute-1.amazonaws.com', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=RF+Baseline (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001D6E1DBF350>, 'Connection to ec2-54-196-109-131.compute-1.amazonaws.com timed out. (connect timeout=120)'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set or create an experiment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRF Baseline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:184\u001b[0m, in \u001b[0;36mset_experiment\u001b[1;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _experiment_lock:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         experiment \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_experiment_by_name(experiment_name)\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment:\n\u001b[0;32m    186\u001b[0m             _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    187\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist. Creating a new experiment.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    188\u001b[0m                 experiment_name,\n\u001b[0;32m    189\u001b[0m             )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:280\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_experiment_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        name: The experiment name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m        :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mget_experiment_by_name(name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:827\u001b[0m, in \u001b[0;36mRestStore.get_experiment_by_name\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    826\u001b[0m     req_body \u001b[38;5;241m=\u001b[39m message_to_json(GetExperimentByName(experiment_name\u001b[38;5;241m=\u001b[39mexperiment_name))\n\u001b[1;32m--> 827\u001b[0m     response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_endpoint(GetExperimentByName, req_body)\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Experiment\u001b[38;5;241m.\u001b[39mfrom_proto(response_proto\u001b[38;5;241m.\u001b[39mexperiment)\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:201\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body, endpoint, retry_timeout_seconds, response_proto)\u001b[0m\n\u001b[0;32m    199\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_METHOD_TO_INFO[api]\n\u001b[0;32m    200\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m response_proto \u001b[38;5;129;01mor\u001b[39;00m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_endpoint(\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_host_creds(),\n\u001b[0;32m    203\u001b[0m     endpoint,\n\u001b[0;32m    204\u001b[0m     method,\n\u001b[0;32m    205\u001b[0m     json_body,\n\u001b[0;32m    206\u001b[0m     response_proto,\n\u001b[0;32m    207\u001b[0m     retry_timeout_seconds\u001b[38;5;241m=\u001b[39mretry_timeout_seconds,\n\u001b[0;32m    208\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:587\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    586\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m--> 587\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:247\u001b[0m, in \u001b[0;36mhttp_request\u001b[1;34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_http_response_with_retries(\n\u001b[0;32m    233\u001b[0m         method,\n\u001b[0;32m    234\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    245\u001b[0m     )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m to:\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with timeout exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m To increase the timeout, set the environment variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMLFLOW_HTTP_REQUEST_TIMEOUT\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m to a larger value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mto\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidURL \u001b[38;5;28;01mas\u001b[39;00m iu:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUrlException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01miu\u001b[39;00m\n",
      "\u001b[1;31mMlflowException\u001b[0m: API request to http://ec2-54-196-109-131.compute-1.amazonaws.com:5000/api/2.0/mlflow/experiments/get-by-name failed with timeout exception HTTPConnectionPool(host='ec2-54-196-109-131.compute-1.amazonaws.com', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=RF+Baseline (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001D6E1DBF350>, 'Connection to ec2-54-196-109-131.compute-1.amazonaws.com timed out. (connect timeout=120)')). To increase the timeout, set the environment variable MLFLOW_HTTP_REQUEST_TIMEOUT (default: 120) to a larger value."
     ]
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "mlflow.set_experiment(\"RF Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "7CyCPT6IhWET",
    "outputId": "607ea721-4d98-45c9-96bd-4ddd5f20e594"
   },
   "outputs": [],
   "source": [
    "# Step 1: Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 2: Define and train a Random Forest baseline model using a simple train-test split\n",
    "with mlflow.start_run() as run:\n",
    "    # Log a description for the run\n",
    "    mlflow.set_tag(\"mlflow.runName\", \"RandomForest_Baseline_TrainTestSplit\")\n",
    "    mlflow.set_tag(\"experiment_type\", \"baseline\")\n",
    "    mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "    # Add a description\n",
    "    mlflow.set_tag(\"description\", \"Baseline RandomForest model for sentiment analysis using Bag of Words (BoW) with a simple train-test split\")\n",
    "\n",
    "    # Log parameters for the vectorizer\n",
    "    mlflow.log_param(\"vectorizer_type\", \"CountVectorizer\")\n",
    "    mlflow.log_param(\"vectorizer_max_features\", vectorizer.max_features)\n",
    "\n",
    "    # Log Random Forest parameters\n",
    "    n_estimators = 200\n",
    "    max_depth = 15\n",
    "\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Log metrics for each class and accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    for label, metrics in classification_rep.items():\n",
    "        if isinstance(metrics, dict):  # For precision, recall, f1-score, etc.\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "\n",
    "    # Save and log the confusion matrix plot\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    mlflow.log_artifact(\"/content/confusion_matrix.png\")\n",
    "\n",
    "    # Log the Random Forest model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "\n",
    "    # Optionally log the dataset itself (if it's small enough)\n",
    "    df.to_csv(\"dataset.csv\", index=False)\n",
    "    mlflow.log_artifact(\"/content/dataset.csv\")\n",
    "\n",
    "# Display final accuracy\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dEHQmkMcbsF",
    "outputId": "73871666-0d3b-415e-9f42-85011180bbda"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGcq_MCujTTK",
    "outputId": "4ad732f7-648d-48a7-aeb8-6f0216942cd3"
   },
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-u_hr_Qcljyg",
    "outputId": "ff5ecb8d-1164-431e-920c-48474d30da0d"
   },
   "outputs": [],
   "source": [
    "!pip install awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwnxM7XclljT",
    "outputId": "87da3364-271a-495b-b28d-d896a7da5095"
   },
   "outputs": [],
   "source": [
    "!aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FJARjXcckS6"
   },
   "outputs": [],
   "source": [
    "df.to_csv('reddit_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SnJl6IRhi38R",
    "outputId": "361abbd6-9ecd-4c20-b892-f7d1aa0feadc"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('reddit_preprocessing.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkTc6t34jCzA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
